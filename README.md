Implementing deep neural networks in R, based on pseudocodes presented in Prof Andrew Ng's 'Deep Learning' specialization.

The final version (Self_NN_v5.R) allows for choices of:

1) Activation functions: sigmoidal, tanh, ReLU and Leaky ReLU
2) Optimization algorithms: Gradient Descent (GD), Exponentially weighted GD, RMSProp based GD and Adam's optimization algorithm
